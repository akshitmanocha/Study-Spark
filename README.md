# Study-Spark: The Agentic Study Buddy

<div align="center">
  <br>
  <img src="https://img.shields.io/badge/Python-3.8+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/Framework-FastAPI-green.svg" alt="Framework">
  <img src="https://img.shields.io/badge/Model-Gemma-red.svg" alt="Model">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License">
</div>


**Study-Spark** is a comprehensive suite of tools designed to revolutionize your study process. By leveraging cutting-edge AI, this project transforms lecture audio and textbook content into high-quality, structured study guides. At its core, Study-Spark is powered by a sophisticated Retrieval-Augmented Generation (RAG) pipeline and a fine-tuned language model, all accessible through an intuitive web interface.

## Core Architecture

The system is built on a modular architecture that seamlessly integrates data processing, model training, and inference.

- **Knowledge Base Creation:** The foundation of Study-Spark is a robust knowledge base created from your textbook.
- **Synthetic Dataset Generation:** To ensure the highest quality summaries, Study-Spark includes a pipeline for generating a synthetic dataset to fine-tune a custom language model.
- **Model Fine-Tuning:** The fine-tuning process enhances the language model's ability to generate domain-specific, high-quality summaries.
- **Inference and Application:** The final step is to bring all the components together in a user-friendly web application.

## Project Artifacts

This project produces several key artifacts that are essential for its operation:

- **FAISS Index:** A highly efficient vector store that contains the embeddings of the textbook content.
- **Fine-Tuning Dataset:** A synthetic dataset generated by the Gemini API, used to fine-tune the language model.
- **Fine-Tuned LoRA Model:** A parameter-efficient fine-tuned model that is optimized for generating high-quality summaries.
- **Web Application:** A user-friendly web interface that allows you to interact with the system.

<div align="center">
  <img src="./artifacts/Screenshot 2025-11-01 at 11.05.06â€¯PM.png" alt="Study-Spark UI">
</div>

## Scope for Improvement

The current version of Study-Spark is a powerful tool, but there are many opportunities for future enhancements.

### 1. Fine-Tuning and Model Optimization

- **Experiment with Larger Models:** While `gemma-3-270m-it` is a solid baseline, using a more powerful model like `gemma-3-9b-it` or other large open-source models could significantly improve performance.
- **Refine the Dataset:** The quality of the fine-tuned model is directly tied to the training data. The synthetic data generation pipeline could be enhanced to create a larger, more diverse, and more accurate dataset.

### 2. RAG Pipeline Enhancements

- **Advanced Retrieval Techniques:** Explore advanced retrieval methods such as **BM25 + FAISS hybrid search** or **SPLADE** to improve the relevance and accuracy of retrieved information.
- **Optimized Chunking Strategies:** Move beyond basic page-level chunking to implement more sophisticated strategies like **semantic chunking**, **fixed-size windowing with overlap**, or even **hierarchical chunking** to better capture context and improve retrieval quality.
- **Improved PDF Text Extraction:** Optimize the PDF text extraction process to handle complex layouts, tables, and figures more accurately, ensuring a higher quality input for the knowledge base.

### 3. Application and User Experience

- **Model Quantization:** To reduce the resource footprint of the fine-tuned model, it could be quantized to a lower precision (e.g., 4-bit or 8-bit), making it faster and more memory-efficient.
- **Streaming Responses:** For a more interactive user experience, the web application could be updated to stream the generated summary in real-time, rather than waiting for the full response.
- **CLI Integration:** In addition to the web interface, a command-line interface (CLI) could be developed to allow for more programmatic and automated use of the system.

## Setup and Installation

1.  **Prerequisites:**
    *   Python 3.8+
    *   An NVIDIA GPU is recommended for training and inference.

2.  **Clone the Repository:**
    ```bash
    git clone https://github.com/akshitmanocha/Study-Spark
    cd Study-Spark
    ```

3.  **Install Dependencies:**
    ```bash
    pip install transformers torch peft datasets mlflow accelerate bitsandbytes fastapi uvicorn python-multipart click soundfile google-generativeai faiss-cpu pypdfium2
    ```
    *(Note: For improved performance on a CUDA-enabled GPU, install the GPU version of FAISS: `pip install faiss-gpu`)*

4.  **Set Up Environment Variables:**
    You will need a Google API key for the Gemini API. Set it as an environment variable:
    ```bash
    export GOOGLE_API_KEY="your-google-api-key"
    ```

## End-to-End Workflow

Follow these steps to process your data, train the model, and run the application.

1.  **Add Your Textbook:**
    Place your textbook (e.g., `UnderstandingDeepLearning.pdf`) in the `data/raw/` directory.

2.  **Extract Text from PDF:**
    ```bash
    python scripts/extract_text_from_pdf.py data/raw/UnderstandingDeepLearning.pdf data/processed/UnderstandingDeepLearning.txt
    ```

3.  **Create the RAG Index:**
    ```bash
    python scripts/create_faiss_index.py
    ```

4.  **Generate the Synthetic Dataset:**
    ```bash
    python scripts/generate_synthetic_dataset.py
    ```

5.  **Train the LoRA Model:**
    ```bash
    python scripts/train_lora_model.py
    ```

6.  **Run the Web Application:**
    ```bash
    cd app/web
    uvicorn main:app --reload
    ```
    You can then access the web interface at [http://127.0.0.1:8000](http://127.0.0.1:8000).
